{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X= np.array([[1, 0, 1, 1],\n",
    "       [1, 1, 1, 0],\n",
    "       [0, 1, 1, 1],\n",
    "       [1, 1, 1, 0],\n",
    "       [1, 1, 1, 0],\n",
    "       [1, 0, 1, 0],\n",
    "       [1, 0, 1, 0],\n",
    "       [0, 1, 1, 1],\n",
    "       [0, 1, 0, 0],\n",
    "       [1, 0, 0, 0]])\n",
    "y= np.array([1, 0, 0, 1, 1, 1, 1, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original entropy: 0.6730116670092565\n"
     ]
    }
   ],
   "source": [
    "# calculate entropy\n",
    "def entropy(y):\n",
    "    N = len(y)\n",
    "    S = np.sum(y)\n",
    "    if S == 0 or S == N:\n",
    "        return 0\n",
    "    else:\n",
    "        return -(S/N)*np.log(S/N) - ((N-S)/N)*np.log((N-S)/N)\n",
    "\n",
    "original_entropy = entropy(y)\n",
    "print(\"original entropy:\", original_entropy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "information gain at attribute 0: 0.38593024420737027\n",
      "information gain at attribute 1: 0.29110316603236885\n",
      "information gain at attribute 2: 0.005131640370881763\n",
      "information gain at attribute 3: 0.06326870451113265\n"
     ]
    }
   ],
   "source": [
    "#SPLIT AT ATTRIBUTE 0\n",
    "y_0_0 = y[X[:,0] == 0]\n",
    "y_0_1 = y[X[:,0] == 1]\n",
    "weight_0_0 = len(y_0_0)/len(y)\n",
    "weight_0_1 = len(y_0_1)/len(y)\n",
    "average_entropy_0 = (weight_0_0*entropy(y_0_0) + weight_0_1*entropy(y_0_1))\n",
    "information_gain_0 = original_entropy - average_entropy_0\n",
    "print(\"information gain at attribute 0:\", information_gain_0)\n",
    "\n",
    "#SPLIT AT ATTRIBUTE 1\n",
    "y_1_0 = y[X[:,1] == 0]\n",
    "y_1_1 = y[X[:,1] == 1]\n",
    "weight_1_0 = len(y_1_0)/len(y)\n",
    "weight_1_1 = len(y_1_1)/len(y)\n",
    "average_entropy_1 = (weight_1_0*entropy(y_1_0) + weight_1_1*entropy(y_1_1))\n",
    "information_gain_1 = original_entropy - average_entropy_1\n",
    "print(\"information gain at attribute 1:\", information_gain_1)\n",
    "\n",
    "#SPLIT AT ATTRIBUTE 2\n",
    "y_2_0 = y[X[:,2] == 0]\n",
    "y_2_1 = y[X[:,2] == 1]\n",
    "weight_2_0 = len(y_2_0)/len(y)\n",
    "weight_2_1 = len(y_2_1)/len(y)\n",
    "average_entropy_2 = (weight_2_0*entropy(y_2_0) + weight_2_1*entropy(y_2_1))\n",
    "information_gain_2 = original_entropy - average_entropy_2\n",
    "print(\"information gain at attribute 2:\", information_gain_2)\n",
    "\n",
    "#SPLIT AT ATTRIBUTE 3\n",
    "y_3_0 = y[X[:,3] == 0]\n",
    "y_3_1 = y[X[:,3] == 1]\n",
    "weight_3_0 = len(y_3_0)/len(y)\n",
    "weight_3_1 = len(y_3_1)/len(y)\n",
    "average_entropy_3 = (weight_3_0*entropy(y_3_0) + weight_3_1*entropy(y_3_1))\n",
    "information_gain_3 = original_entropy - average_entropy_3\n",
    "print(\"information gain at attribute 3:\", information_gain_3)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "train_X= np.array([[ -7.983,   0.318,   1.177,  -0.075],\n",
    "       [ -2.288,  -2.97 ,   1.557,  -3.241],\n",
    "       [ -1.622,  11.014,   8.631,  -2.069],\n",
    "       [ -5.75 ,   1.011,  14.284,  -3.099],\n",
    "       [  0.935,  10.975,   7.959,  -4.048],\n",
    "       [ -1.541,   7.003,  10.552,  -4.558],\n",
    "       [ -0.344,   2.407,  -1.054,  -4.026],\n",
    "       [ -1.759,  -0.67 ,   0.562,  -3.613],\n",
    "       [ -1.126,  -4.047,   0.892,  -5.193],\n",
    "       [ -2.327,  10.837,  11.682,  -2.213],\n",
    "       [ -0.62 ,   4.928,  -0.732,  -4.64 ],\n",
    "       [ -4.242,   7.423,  13.282,  -3.703],\n",
    "       [ -1.113,   0.456,  -0.799,  -1.842],\n",
    "       [ -0.161,   6.286,  -1.838,  -5.591],\n",
    "       [ -2.592,   7.778,  12.245,  -7.002],\n",
    "       [ -9.281,   2.353,   2.221,   0.251],\n",
    "       [ -4.728,   5.334,  12.346,  -3.496],\n",
    "       [  0.112,   3.716,   0.639,  -3.831],\n",
    "       [ -8.759,  -0.261,   0.884,  -1.335],\n",
    "       [ -3.675,   5.358,  11.416,  -3.644],\n",
    "       [-12.174,  -4.295,   3.39 ,   1.336],\n",
    "       [-11.718,  -3.836,   4.766,  -0.191],\n",
    "       [ -1.28 ,  -0.809,   1.332,  -3.63 ],\n",
    "       [ -4.129,   9.484,   9.761,  -1.132],\n",
    "       [ -9.579,  -4.656,   2.802,  -0.113],\n",
    "       [ -0.989,  11.243,  11.439,  -5.824],\n",
    "       [ -8.123,  -0.8  ,   1.128,  -3.451],\n",
    "       [ -5.206,   5.337,  12.67 ,  -2.111],\n",
    "       [  0.961,   2.63 ,   0.075,  -4.746],\n",
    "       [ -1.63 ,   7.706,  10.048,  -4.133]])\n",
    "train_y= np.array([0, 2, 1, 1, 1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 1, 0, 1, 2, 0, 1, 0, 0, 2, 1, 0, 1, 0, 1, 2, 1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict prob: [[0.    0.999 0.001]\n",
      " [0.998 0.001 0.001]\n",
      " [0.    0.978 0.022]\n",
      " [0.998 0.001 0.002]]\n",
      "predict: [0 0 0 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_X, train_y)\n",
    "\n",
    "test_x_0 =np.array([[ -2.457,   5.452,  13.113,  -4.819],\n",
    "       [-10.195,  -0.629,   1.65 ,   0.67 ],\n",
    "       [  0.571,   8.576,   9.002,  -6.633],\n",
    "       [-10.688,  -3.278,   2.541,  -1.588]])\n",
    "predict_prob = clf.predict_proba(test_x_0)\n",
    "predict_prob_round = np.round(predict_prob, decimals=3)\n",
    "print(\"predict prob:\", predict_prob_round)\n",
    "\n",
    "test_x_1 =np.array([[ -8.261,  -0.965,   1.238,  -2.658],\n",
    "       [-10.909,  -3.602,   4.091,  -0.242],\n",
    "       [ -9.492,  -0.179,   0.412,   1.098],\n",
    "       [ -0.863,   3.818,  -2.278,  -2.43 ]])\n",
    "\n",
    "print(\"predict:\",clf.predict(test_x_1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "support vectors: [[ 6.333 -1.85 ]\n",
      " [ 5.073 -5.974]]\n",
      "support vector indices: [13 12]\n",
      "support vectors: [[ 7.478 -1.931]\n",
      " [ 6.333 -1.85 ]\n",
      " [ 5.786 -1.645]\n",
      " [ 6.46  -1.797]\n",
      " [ 5.168 -6.587]\n",
      " [ 5.073 -5.974]\n",
      " [ 3.938 -5.907]\n",
      " [ 7.461 -6.705]]\n",
      "support vector indices: [ 4 13 22 23 11 12 14 21]\n",
      "support vector count: [4 4]\n"
     ]
    }
   ],
   "source": [
    "train_X=np.array([[ 3.957, -7.186],\n",
    "       [ 6.857, -0.822],\n",
    "       [ 6.582, -1.077],\n",
    "       [ 4.654, -7.987],\n",
    "       [ 7.478, -1.931],\n",
    "       [ 5.428, -8.313],\n",
    "       [ 3.565, -7.913],\n",
    "       [ 6.7  , -1.363],\n",
    "       [ 4.623, -6.801],\n",
    "       [ 6.033, -8.493],\n",
    "       [ 6.548, -1.566],\n",
    "       [ 5.168, -6.587],\n",
    "       [ 5.073, -5.974],\n",
    "       [ 6.333, -1.85 ],\n",
    "       [ 3.938, -5.907],\n",
    "       [ 6.813, -1.383],\n",
    "       [ 6.556, -1.512],\n",
    "       [ 6.578,  0.456],\n",
    "       [ 4.682, -8.089],\n",
    "       [ 5.265, -0.599],\n",
    "       [ 3.721, -6.856],\n",
    "       [ 7.461, -6.705],\n",
    "       [ 5.786, -1.645],\n",
    "       [ 6.46 , -1.797],\n",
    "       [ 3.65 , -8.249],\n",
    "       [ 9.457, -0.393],\n",
    "       [ 2.895, -8.154],\n",
    "       [ 7.965, -1.29 ],\n",
    "       [ 3.926, -9.202],\n",
    "       [ 8.016, -0.418]])\n",
    "train_y=np.array([1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0])\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "#linear kernel\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(train_X, train_y)\n",
    "#get support vectors\n",
    "print(\"support vectors:\", clf.support_vectors_)\n",
    "print(\"support vector indices:\", clf.support_)\n",
    "\n",
    "#rbf kernel\n",
    "clf = SVC(kernel='rbf')\n",
    "clf.fit(train_X, train_y)\n",
    "#get support vectors\n",
    "print(\"support vectors:\", clf.support_vectors_)\n",
    "print(\"support vector indices:\", clf.support_)\n",
    "print(\"support vector count:\", clf.n_support_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "data = np.load('finalnn_data.npz')\n",
    "train_X = data['train_X']\n",
    "train_y = data['train_y']\n",
    "valid_X = data['valid_X']\n",
    "valid_y = data['valid_y']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 20)                220       \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 20)                420       \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 3)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 703\n",
      "Trainable params: 703\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "inputs = layers.Input(shape=(10,))\n",
    "x = layers.Dense(20, activation='relu')(inputs)\n",
    "x = layers.Dense(20, activation='relu')(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "outputs = layers.Dense(3, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.4612 - accuracy: 0.3273 - val_loss: 1.0174 - val_accuracy: 0.4880\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 1.0052 - accuracy: 0.5220 - val_loss: 0.8394 - val_accuracy: 0.6740\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.8253 - accuracy: 0.6300 - val_loss: 0.7092 - val_accuracy: 0.7240\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.6993 - val_loss: 0.6077 - val_accuracy: 0.7640\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5896 - accuracy: 0.7727 - val_loss: 0.4996 - val_accuracy: 0.8480\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.8313 - val_loss: 0.4071 - val_accuracy: 0.8880\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.3837 - accuracy: 0.8747 - val_loss: 0.3476 - val_accuracy: 0.8940\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.3390 - accuracy: 0.8880 - val_loss: 0.2974 - val_accuracy: 0.9000\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2854 - accuracy: 0.9013 - val_loss: 0.2682 - val_accuracy: 0.9120\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2664 - accuracy: 0.9073 - val_loss: 0.2485 - val_accuracy: 0.9180\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2356 - accuracy: 0.9300 - val_loss: 0.2380 - val_accuracy: 0.9140\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2200 - accuracy: 0.9240 - val_loss: 0.2188 - val_accuracy: 0.9180\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.2048 - accuracy: 0.9280 - val_loss: 0.2069 - val_accuracy: 0.9220\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1955 - accuracy: 0.9373 - val_loss: 0.1995 - val_accuracy: 0.9240\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1846 - accuracy: 0.9347 - val_loss: 0.1871 - val_accuracy: 0.9260\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1880 - accuracy: 0.9367 - val_loss: 0.1845 - val_accuracy: 0.9300\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1744 - accuracy: 0.9380 - val_loss: 0.1820 - val_accuracy: 0.9260\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1642 - accuracy: 0.9347 - val_loss: 0.1709 - val_accuracy: 0.9380\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1564 - accuracy: 0.9433 - val_loss: 0.1680 - val_accuracy: 0.9440\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1501 - accuracy: 0.9393 - val_loss: 0.1737 - val_accuracy: 0.9360\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1461 - accuracy: 0.9480 - val_loss: 0.1678 - val_accuracy: 0.9340\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1472 - accuracy: 0.9460 - val_loss: 0.1673 - val_accuracy: 0.9380\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1416 - accuracy: 0.9460 - val_loss: 0.1614 - val_accuracy: 0.9400\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1403 - accuracy: 0.9433 - val_loss: 0.1640 - val_accuracy: 0.9320\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1349 - accuracy: 0.9460 - val_loss: 0.1715 - val_accuracy: 0.9340\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1256 - accuracy: 0.9567 - val_loss: 0.1627 - val_accuracy: 0.9360\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1271 - accuracy: 0.9480 - val_loss: 0.1551 - val_accuracy: 0.9440\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1232 - accuracy: 0.9527 - val_loss: 0.1593 - val_accuracy: 0.9360\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1203 - accuracy: 0.9560 - val_loss: 0.1587 - val_accuracy: 0.9400\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1200 - accuracy: 0.9547 - val_loss: 0.1518 - val_accuracy: 0.9460\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1139 - accuracy: 0.9607 - val_loss: 0.1594 - val_accuracy: 0.9380\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1055 - accuracy: 0.9653 - val_loss: 0.1503 - val_accuracy: 0.9420\n",
      "Epoch 33/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1175 - accuracy: 0.9533 - val_loss: 0.1547 - val_accuracy: 0.9420\n",
      "Epoch 34/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1146 - accuracy: 0.9560 - val_loss: 0.1576 - val_accuracy: 0.9360\n",
      "Epoch 35/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1161 - accuracy: 0.9547 - val_loss: 0.1562 - val_accuracy: 0.9360\n",
      "Epoch 36/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1012 - accuracy: 0.9613 - val_loss: 0.1520 - val_accuracy: 0.9420\n",
      "Epoch 37/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1058 - accuracy: 0.9593 - val_loss: 0.1514 - val_accuracy: 0.9420\n",
      "Epoch 38/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0981 - accuracy: 0.9647 - val_loss: 0.1490 - val_accuracy: 0.9460\n",
      "Epoch 39/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1111 - accuracy: 0.9600 - val_loss: 0.1493 - val_accuracy: 0.9460\n",
      "Epoch 40/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1083 - accuracy: 0.9587 - val_loss: 0.1598 - val_accuracy: 0.9320\n",
      "Epoch 41/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1120 - accuracy: 0.9567 - val_loss: 0.1601 - val_accuracy: 0.9380\n",
      "Epoch 42/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1052 - accuracy: 0.9607 - val_loss: 0.1495 - val_accuracy: 0.9440\n",
      "Epoch 43/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0989 - accuracy: 0.9667 - val_loss: 0.1483 - val_accuracy: 0.9420\n",
      "Epoch 44/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1040 - accuracy: 0.9547 - val_loss: 0.1538 - val_accuracy: 0.9480\n",
      "Epoch 45/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.1008 - accuracy: 0.9607 - val_loss: 0.1499 - val_accuracy: 0.9420\n",
      "Epoch 46/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0959 - accuracy: 0.9680 - val_loss: 0.1475 - val_accuracy: 0.9440\n",
      "Epoch 47/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0949 - accuracy: 0.9633 - val_loss: 0.1487 - val_accuracy: 0.9440\n",
      "Epoch 48/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0968 - accuracy: 0.9640 - val_loss: 0.1493 - val_accuracy: 0.9460\n",
      "Epoch 49/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0943 - accuracy: 0.9640 - val_loss: 0.1542 - val_accuracy: 0.9420\n",
      "Epoch 50/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0971 - accuracy: 0.9640 - val_loss: 0.1524 - val_accuracy: 0.9440\n",
      "Epoch 51/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0929 - accuracy: 0.9647 - val_loss: 0.1523 - val_accuracy: 0.9460\n",
      "Epoch 52/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0900 - accuracy: 0.9660 - val_loss: 0.1606 - val_accuracy: 0.9420\n",
      "Epoch 53/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0922 - accuracy: 0.9687 - val_loss: 0.1524 - val_accuracy: 0.9460\n",
      "Epoch 54/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0965 - accuracy: 0.9627 - val_loss: 0.1490 - val_accuracy: 0.9460\n",
      "Epoch 55/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0896 - accuracy: 0.9660 - val_loss: 0.1490 - val_accuracy: 0.9440\n",
      "Epoch 56/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0814 - accuracy: 0.9707 - val_loss: 0.1637 - val_accuracy: 0.9360\n",
      "Epoch 57/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0825 - accuracy: 0.9707 - val_loss: 0.1469 - val_accuracy: 0.9460\n",
      "Epoch 58/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0830 - accuracy: 0.9713 - val_loss: 0.1526 - val_accuracy: 0.9460\n",
      "Epoch 59/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0836 - accuracy: 0.9680 - val_loss: 0.1558 - val_accuracy: 0.9440\n",
      "Epoch 60/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0825 - accuracy: 0.9700 - val_loss: 0.1523 - val_accuracy: 0.9400\n",
      "Epoch 61/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0771 - accuracy: 0.9740 - val_loss: 0.1472 - val_accuracy: 0.9440\n",
      "Epoch 62/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0897 - accuracy: 0.9667 - val_loss: 0.1504 - val_accuracy: 0.9460\n",
      "Epoch 63/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0850 - accuracy: 0.9673 - val_loss: 0.1490 - val_accuracy: 0.9440\n",
      "Epoch 64/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0800 - accuracy: 0.9720 - val_loss: 0.1485 - val_accuracy: 0.9500\n",
      "Epoch 65/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0906 - accuracy: 0.9660 - val_loss: 0.1475 - val_accuracy: 0.9500\n",
      "Epoch 66/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0848 - accuracy: 0.9713 - val_loss: 0.1458 - val_accuracy: 0.9520\n",
      "Epoch 67/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0735 - accuracy: 0.9760 - val_loss: 0.1477 - val_accuracy: 0.9460\n",
      "Epoch 68/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0756 - accuracy: 0.9747 - val_loss: 0.1492 - val_accuracy: 0.9460\n",
      "Epoch 69/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0764 - accuracy: 0.9760 - val_loss: 0.1500 - val_accuracy: 0.9440\n",
      "Epoch 70/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0774 - accuracy: 0.9733 - val_loss: 0.1444 - val_accuracy: 0.9520\n",
      "Epoch 71/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0767 - accuracy: 0.9700 - val_loss: 0.1468 - val_accuracy: 0.9440\n",
      "Epoch 72/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0701 - accuracy: 0.9747 - val_loss: 0.1475 - val_accuracy: 0.9500\n",
      "Epoch 73/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0712 - accuracy: 0.9720 - val_loss: 0.1461 - val_accuracy: 0.9460\n",
      "Epoch 74/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0772 - accuracy: 0.9713 - val_loss: 0.1467 - val_accuracy: 0.9460\n",
      "Epoch 75/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0705 - accuracy: 0.9753 - val_loss: 0.1492 - val_accuracy: 0.9440\n",
      "Epoch 76/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0685 - accuracy: 0.9733 - val_loss: 0.1504 - val_accuracy: 0.9460\n",
      "Epoch 77/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0786 - accuracy: 0.9720 - val_loss: 0.1541 - val_accuracy: 0.9480\n",
      "Epoch 78/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0761 - accuracy: 0.9707 - val_loss: 0.1533 - val_accuracy: 0.9460\n",
      "Epoch 79/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0651 - accuracy: 0.9767 - val_loss: 0.1466 - val_accuracy: 0.9460\n",
      "Epoch 80/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0663 - accuracy: 0.9767 - val_loss: 0.1472 - val_accuracy: 0.9460\n",
      "Epoch 81/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.9760 - val_loss: 0.1521 - val_accuracy: 0.9480\n",
      "Epoch 82/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.9760 - val_loss: 0.1466 - val_accuracy: 0.9480\n",
      "Epoch 83/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0668 - accuracy: 0.9793 - val_loss: 0.1541 - val_accuracy: 0.9460\n",
      "Epoch 84/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0709 - accuracy: 0.9760 - val_loss: 0.1439 - val_accuracy: 0.9520\n",
      "Epoch 85/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.9720 - val_loss: 0.1496 - val_accuracy: 0.9480\n",
      "Epoch 86/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0665 - accuracy: 0.9733 - val_loss: 0.1511 - val_accuracy: 0.9500\n",
      "Epoch 87/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0659 - accuracy: 0.9747 - val_loss: 0.1495 - val_accuracy: 0.9440\n",
      "Epoch 88/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.9760 - val_loss: 0.1525 - val_accuracy: 0.9400\n",
      "Epoch 89/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.9793 - val_loss: 0.1477 - val_accuracy: 0.9460\n",
      "Epoch 90/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0542 - accuracy: 0.9820 - val_loss: 0.1480 - val_accuracy: 0.9440\n",
      "Epoch 91/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0651 - accuracy: 0.9727 - val_loss: 0.1486 - val_accuracy: 0.9440\n",
      "Epoch 92/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0646 - accuracy: 0.9747 - val_loss: 0.1455 - val_accuracy: 0.9460\n",
      "Epoch 93/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0604 - accuracy: 0.9753 - val_loss: 0.1453 - val_accuracy: 0.9440\n",
      "Epoch 94/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0616 - accuracy: 0.9760 - val_loss: 0.1566 - val_accuracy: 0.9420\n",
      "Epoch 95/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.9793 - val_loss: 0.1496 - val_accuracy: 0.9520\n",
      "Epoch 96/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.9807 - val_loss: 0.1527 - val_accuracy: 0.9540\n",
      "Epoch 97/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0539 - accuracy: 0.9780 - val_loss: 0.1501 - val_accuracy: 0.9440\n",
      "Epoch 98/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0546 - accuracy: 0.9827 - val_loss: 0.1512 - val_accuracy: 0.9460\n",
      "Epoch 99/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0521 - accuracy: 0.9787 - val_loss: 0.1565 - val_accuracy: 0.9480\n",
      "Epoch 100/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.0607 - accuracy: 0.9800 - val_loss: 0.1564 - val_accuracy: 0.9460\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1bca6829400>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(train_X, train_y, epochs=100, batch_size=32,validation_data=(valid_X, valid_y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}