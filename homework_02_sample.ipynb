{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<hr style=\"height:1px;border:none;color:#333;background-color:#333;\" />\n",
    "\n",
    "### Q3. 在scikit-learn裡，定義自己的分類器類別myGaussianClassifier\n",
    "在這個作業，我們假設$P(X|C=i),\\forall i$呈現高斯分佈$\\mathcal{N}(\\boldsymbol{\\mu}_{i},\\boldsymbol{\\Sigma}_{i})$。你必須完成下面函式，才能將myGaussianClassifier放在scikit-learn框架下。前三個函式($\\text{__init__,fit,predict}$)是必要的，後面是視需要再增加。那三個函式需要傳回的值請參照<br>\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html <br>\n",
    "的說明撰寫。\n",
    "\n",
    "\n",
    "+ $\\text{__init__(self,alpha=1e-5)}$函式參數必須包含所有需要設定的參數及其內定值，其中$alpha$為正則化參數用於正則化sample covariance matrix。\n",
    "+ fit(self,train,target): 你必須對每一個類別完成估計$\\boldsymbol{\\mu}_{i},\\boldsymbol{\\Sigma}_{i},P(C_{i})$,其中$\\boldsymbol{\\Sigma}_{i}=\\text{the sample covariance matrix of class $i$}+\\alpha\\mathbf{I}$。若是target裡，類別標籤為0,1,2,...,c-1，你可以用np.mean,np.cov得到你要的sample mean, sample covariance matrix(參照Multivariate Methods那章，估計sample mean, sample covariance matrix的公式):\n",
    "   + **sample mean**: $m_{i}$=np.mean(X[np.nonzero(target.ravel()==i)],axis=0)\n",
    "   + **sample covariance matrix**: $S_{i}$=np.cov(X[np.nonzero(target.ravel()==i)],rowvar=False)+alpha*np.eye(X.shape[1])\n",
    "   + **prior**: $P(C=i)$= np.sum(target.ravel()==i)/target.size\n",
    "   \n",
    "   \n",
    "+ predict(self,X,y=None)裡必須計算$X$裡，每一列資料的事後機率$P(C=i|x),\\forall i$，選擇事後機率高的那個類別為x的類別。\n",
    "+ predict_proba(self,X,y=None)計算每一列資料的事後機率$P(C|x)$。\n",
    "+ score(self,X,y)計算這個模型資料為X，答案為y的得到的評分(越高分代表越好喔，例如準確度)\n",
    "\n",
    "<hr style=\"height:1px;border:none;color:#333;background-color:#333;\" />\n",
    "\n",
    "### Q3.1 請完成myGaussianClassifier程式。\n",
    "<pre>\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class myGaussianClassifier(BaseEstimator, ClassifierMixin): #必須繼承 BaseEstimator, ClassifierMixin\n",
    "    def __init__(self,alpha=1.e-5):        # initializer函式參數必須包含所有需要設定的參數及其內定值\n",
    "        if isinstance(self,myGaussianClassifier):\n",
    "            super(myGaussianClassifier,self).__init__()  \n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def fit(self,train,target): # 不能缺\n",
    "        #    \n",
    "        N,d = train.shape\n",
    "        label = np.sort(np.unique(target.ravel()))\n",
    "        self.c_     = label.size\n",
    "        self.d_     = d\n",
    "        self.prior_ = np.zeros((self.c_,))\n",
    "        self.mean_  = np.zeros((self.c_,self.d_))\n",
    "        self.cov_   = np.zeros((self.c_,self.d_,self.d_))\n",
    "        # 計算 mean, covariance\n",
    "        for cid,y in enumerate(label):\n",
    "            idx = np.nonzero(target.ravel()==y)\n",
    "            self.cov_[cid] =np.cov(train[idx],rowvar=False)+self.alpha*np.eye(d)\n",
    "            # 完成mean及prior\n",
    "            \n",
    "        return self #最後要傳回self這個物件\n",
    " \n",
    "    def predict(self,X, y=None): # 不能缺\n",
    "        pass\n",
    "    \n",
    "    def predict_proba(self,X, y=None): # 視需要\n",
    "        pass\n",
    "    \n",
    "    def score(self,X,y): # 可有可無\n",
    "        pass\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<hr style=\"height:1px;border:none;color:#333;background-color:#333;\" />\n",
    "\n",
    "### Q3.2,Q3.3 使用GridSearchCV與cross_val_score評估其效能 (如同作業一)，並比較其準確度相較於GaussianNB、kNN與SVC有沒有顯著差異\n",
    "在這個作業，你要比較的是下面分類器，並使用GridSearchCV選取恰當超參數，cv設定為5:\n",
    "+ SVC: {'kernel':['linear'],'C':[0.01, 0.1, 1, 10]}\n",
    "+ KNeighborsClassifier: {'n_neighbors':[1,3,5,7]}\n",
    "+ myGaussian: {'alpha':[0.001,0.01,0.1,1,10,100]}\n",
    "+ GaussianNB: {'var_smoothing':[1e-5,1e-4,1e-3,1e-2,1e-1,1]}\n",
    "\n",
    "你要回答的問題:\n",
    "### Q3.2 myGaussianClassifier, SVC with linear kernel, kNN, GaussianNB平均準確分別為多少?\n",
    "### Q3.3 以paired t-test顯著程度0.05前提下，平均準確率最高那個分類器與另外3個分類器，在平均準確率上有顯著差異嗎? 請寫出p-value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn import neighbors, svm, naive_bayes \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sklearn.datasets as ds\n",
    "import numpy as np\n",
    "\n",
    "# 載入資料集\n",
    "data,target    = ds.load_breast_cancer(True)\n",
    " \n",
    "# 宣告分類器\n",
    "gauss_clf      = myGaussianClassifier()\n",
    "knn_clf        = neighbors.KNeighborsClassifier(n_neighbors=3,weights='uniform',algorithm='kd_tree',leaf_size=30)\n",
    "svm_clf        = svm.SVC(kernel='linear', C=1, probability=True)\n",
    "gaussnb_clf    = naive_bayes.GaussianNB()\n",
    "\n",
    "# 定義超參數及其候選值\n",
    "knn_clf_param = {'n_neighbors':[1,3,5,7]}\n",
    "svm_clf_param = {'C':[0.01, 0.1, 1, 10]}\n",
    "gauss_clf_param={'alpha':[0.001,0.01,0.1,1,10,100]}\n",
    "gaussnb_clf_param={'var_smoothing':np.logspace(-5,2,6)}\n",
    "\n",
    "# inner cross-validation for hyper-parameter tuning\n",
    "# 當n_jobs=-1時，在Windows可能有Bug，那麼就改為n_jobs = 1\n",
    "gauss_gs     = GridSearchCV(estimator=gauss_clf,param_grid = gauss_clf_param, scoring = 'accuracy', cv=5, n_jobs=-1, verbose=1)\n",
    "knn_gs       = GridSearchCV(estimator=knn_clf,param_grid = knn_clf_param, scoring = 'accuracy', cv=5, n_jobs=-1, verbose=1)\n",
    "svm_gs       = GridSearchCV(estimator=svm_clf,param_grid = svm_clf_param, scoring = 'accuracy', cv=5,  n_jobs=-1, verbose=1)\n",
    "svm_pipeline = Pipeline([('scaler',MinMaxScaler()),('svm_gs',svm_gs)])\n",
    "gaussnb_gs   = GridSearchCV(estimator=gaussnb_clf,param_grid = gaussnb_clf_param, scoring = 'accuracy', cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# outer cross-validation for estimating the accuracy of the classifier\n",
    "# the classifiers to be compared must be evaluated by the same k-fold CV\n",
    "kfold        = StratifiedKFold(n_splits=10, shuffle=True, random_state=3)\n",
    "\n",
    "#當n_jobs=-1時，在Windows可能有Bug，那麼就改為n_jobs = 1\n",
    "gauss_scores   = cross_val_score(gauss_gs, data, target, scoring='accuracy',cv = kfold, verbose=10) \n",
    "knn_scores     = cross_val_score(knn_gs, data, target, scoring='accuracy',cv = kfold, verbose=10)\n",
    "svm_scores     = cross_val_score(svm_pipeline, data, target, scoring='accuracy',cv = kfold, verbose=10)\n",
    "gaussnb_scores = cross_val_score(gaussnb_gs, data, target, scoring='accuracy',cv = kfold, verbose=10)\n",
    "\n",
    "#請同學接續寫完評比\n",
    "# apply the paired t-test (Refer to ppt for Chapter 20 Design and Analysis of Machine Learning Experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 效能評估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}